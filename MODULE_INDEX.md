# ðŸ“š Complete Module Index & Navigation

## ðŸŽ¯ Quick Navigation

| If you want to... | See this file | Section |
|-------------------|--------------|---------|
| **Get started** | [QUICKSTART.md](QUICKSTART.md) | All sections |
| **Understand architecture** | [MODULAR_ARCHITECTURE.md](MODULAR_ARCHITECTURE.md) | Module Structure |
| **See dependencies** | [DEPENDENCY_MAP.md](DEPENDENCY_MAP.md) | Dependency Hierarchy |
| **Run the pipeline** | [pipeline.py](pipeline.py) | Lines 1-50 |
| **Configure settings** | [config.py](config.py) | All sections |
| **Process text** | [chunker.py](chunker.py) | `chunk_text()` method |
| **Analyze consistency** | [rag_analyzer.py](rag_analyzer.py) | `ConsistencyAnalyzer` class |
| **Find contradictions** | [negation_finder.py](negation_finder.py) | `find_negated_chunks()` |
| **Understand data structures** | [models.py](models.py) | All dataclasses |

## ðŸ“‚ File Organization

```
.
â”œâ”€â”€ ðŸš€ EXECUTION LAYER
â”‚   â”œâ”€â”€ rag_advanced.py           [30 lines]   Backward compatibility wrapper
â”‚   â””â”€â”€ pipeline.py               [280 lines]  Main orchestrator (NEW ENTRY POINT)
â”‚
â”œâ”€â”€ ðŸ”§ CONFIGURATION LAYER  
â”‚   â””â”€â”€ config.py                 [110 lines]  All settings & NLP initialization
â”‚
â”œâ”€â”€ ðŸ“¦ DATA LAYER
â”‚   â””â”€â”€ models.py                 [50 lines]   ChunkMetadata, BackstoryClaim, etc.
â”‚
â”œâ”€â”€ ðŸ§  PROCESSING LAYER
â”‚   â”œâ”€â”€ chunker.py                [90 lines]   Text â†’ Chunks + Graphs
â”‚   â”œâ”€â”€ context_builder.py        [140 lines]  Embeddings â†’ Context Vectors
â”‚   â””â”€â”€ index_manager.py          [170 lines]  Build & cache corpus
â”‚
â”œâ”€â”€ ðŸ”Œ EXTERNAL SERVICES LAYER
â”‚   â”œâ”€â”€ nvidia_client.py          [95 lines]   API wrapper for embeddings & LLM
â”‚   â””â”€â”€ negation_finder.py        [70 lines]   LLM-based contradiction detection
â”‚
â”œâ”€â”€ ðŸ“Š REASONING LAYER
â”‚   â”œâ”€â”€ graph_rag.py              [120 lines]  Multi-hop graph reasoning
â”‚   â””â”€â”€ rag_analyzer.py           [230 lines]  Claim extraction & analysis
â”‚
â””â”€â”€ ðŸ“– DOCUMENTATION LAYER
    â”œâ”€â”€ REFACTORING_SUMMARY.md                What was done & why
    â”œâ”€â”€ MODULAR_ARCHITECTURE.md               Detailed architecture guide
    â”œâ”€â”€ QUICKSTART.md                         Usage examples & tips
    â”œâ”€â”€ DEPENDENCY_MAP.md                     Visual dependencies
    â””â”€â”€ MODULE_INDEX.md                       This file!
```

## ðŸŽ¯ Module Quick Reference

### 1ï¸âƒ£ config.py - The Foundation
```python
# What it does:
- Initializes spaCy and NLTK
- Loads environment variables
- Defines all constants and thresholds
- Sets up logging

# Key imports:
from config import (
    NVIDIA_API_KEY, EMBEDDING_DIM, DEFAULT_CHUNK_SIZE,
    SIMILARITY_THRESHOLD, nlp
)

# When to modify:
- Change model parameters
- Adjust chunking size
- Update API thresholds
- Configure paths
```

### 2ï¸âƒ£ models.py - The Blueprint
```python
# What it does:
- Defines data structures
- Type hints for all components
- Clear contracts between modules

# Key classes:
- ChunkMetadata: Narrative chunks with metadata
- BackstoryClaim: Extracted backstory statements
- ConsistencyAnalysis: Analysis results

# When to modify:
- Add new metadata fields
- Change data structure
- Extend analysis results
```

### 3ï¸âƒ£ nvidia_client.py - The Gateway
```python
# What it does:
- Abstracts NVIDIA NIM API calls
- Handles authentication
- Manages batch requests

# Key methods:
- embed(texts): Get embeddings
- chat(messages): Get LLM responses

# When to modify:
- Switch to different LLM backend
- Add retry logic
- Implement caching
```

### 4ï¸âƒ£ chunker.py - The Segmenter
```python
# What it does:
- Breaks text into semantic chunks
- Uses spaCy dependency parsing
- Builds dependency graphs

# Key method:
- chunk_text(text): Text â†’ Chunks

# When to modify:
- Change chunking strategy
- Adjust chunk size
- Implement recursive splitting
```

### 5ï¸âƒ£ context_builder.py - The Enhancer
```python
# What it does:
- Augments embeddings with context
- Extracts sentiment, temporal, causal signals
- Normalizes vectors

# Key method:
- build_context_vector(text, embedding): Enhanced vector

# When to modify:
- Add new signal types
- Change sentiment analysis
- Adjust vector composition
```

### 6ï¸âƒ£ negation_finder.py - The Contradictions
```python
# What it does:
- Finds narrative contradictions
- Uses LLM to find opposites
- Detects semantic negations

# Key method:
- find_negated_chunks(claim, chunks, embeddings): Contradictions

# When to modify:
- Change negation strategy
- Adjust similarity threshold
- Implement custom contradiction logic
```

### 7ï¸âƒ£ graph_rag.py - The Reasoner
```python
# What it does:
- Builds semantic similarity graph
- Performs multi-hop searches
- Finds reasoning paths

# Key methods:
- multi_hop_search(): Related chunks
- find_reasoning_path(): Connection paths

# When to modify:
- Change similarity threshold
- Adjust graph construction
- Implement custom traversal
```

### 8ï¸âƒ£ index_manager.py - The Storage
```python
# What it does:
- Builds corpus from books
- Caches with pickle
- Loads and indexes text

# Key methods:
- load_or_build(): Load or create index
- get_corpus(): Access chunks
- get_graph_rag(): Access graphs

# When to modify:
- Change caching strategy
- Add database support
- Implement versioning
```

### 9ï¸âƒ£ rag_analyzer.py - The Analysis
```python
# What it does:
- Extracts backstory claims
- Retrieves supporting evidence
- Reasons about consistency with LLM

# Key classes:
- BackstoryExtractor: Parse backstories
- ConsistencyAnalyzer: Reasoning logic

# When to modify:
- Change claim extraction
- Adjust retrieval parameters
- Modify reasoning prompts
```

### ðŸ”Ÿ pipeline.py - The Orchestrator
```python
# What it does:
- Coordinates all components
- Manages pipeline execution
- Handles input/output

# Key class:
- AdvancedNarrativeConsistencyRAG: Main class

# Entry point:
- run_pipeline(): Execute full analysis

# When to modify:
- Change pipeline flow
- Add preprocessing steps
- Implement batching
```

## ðŸ”„ Data Flow Examples

### Example 1: Process Raw Text
```python
from chunker import DependencyChunker
from context_builder import ContextVectorBuilder
from nvidia_client import NVIDIAClient

# 1. Setup
client = NVIDIAClient(api_key, base_url)
chunker = DependencyChunker()
builder = ContextVectorBuilder()

# 2. Chunk text
chunks = chunker.chunk_text("Your text here...")

# 3. Embed
embeddings = client.embed([c[0] for c in chunks])

# 4. Enhance
for text, embedding in zip([c[0] for c in chunks], embeddings):
    context_vec = builder.build_context_vector(text, embedding)
```

### Example 2: Analyze Backstory
```python
from pipeline import AdvancedNarrativeConsistencyRAG

# 1. Initialize
rag = AdvancedNarrativeConsistencyRAG()

# 2. Load corpus
rag.index_manager.load_or_build()

# 3. Create backstory
backstory = {
    "early_events": ["Event 1", "Event 2"],
    "beliefs": ["Belief 1"],
    "motivations": ["Motivation 1"],
    "fears": [],
    "assumptions_about_world": []
}

# 4. Analyze
result = rag.analyze_backstory("book_key", "Character", backstory)

# 5. Access results
print(f"Consistent: {result.prediction == 1}")
print(f"Confidence: {result.confidence:.2%}")
print(f"Reasoning: {result.reasoning}")
```

### Example 3: Find Contradictions
```python
from negation_finder import SemanticNegationFinder
import numpy as np

finder = SemanticNegationFinder(client)

claim = "The character is brave"
chunks = ["The character is afraid", "The character showed courage"]
embeddings = np.array(client.embed(chunks))

contradictions = finder.find_negated_chunks(claim, chunks, embeddings)
for idx, score in contradictions:
    print(f"Contradicts: {chunks[idx]} (score: {score:.3f})")
```

## ðŸ§ª Testing Each Module

```python
# Test chunker
from chunker import DependencyChunker
chunker = DependencyChunker()
chunks = chunker.chunk_text("Test text.")
assert len(chunks) > 0

# Test context builder
from context_builder import ContextVectorBuilder
import numpy as np
builder = ContextVectorBuilder()
vec = builder.build_context_vector("Test", np.random.rand(1024))
assert vec.shape == (1024,)
assert np.linalg.norm(vec) <= 1.01

# Test NVIDIA client
from nvidia_client import NVIDIAClient
client = NVIDIAClient(api_key, base_url)
embeddings = client.embed(["test"])
assert embeddings.shape[0] == 1

# Test models
from models import ChunkMetadata
assert hasattr(ChunkMetadata, 'text')
assert hasattr(ChunkMetadata, 'embedding')
```

## ðŸš€ Common Workflows

| Workflow | Command |
|----------|---------|
| **Full pipeline** | `python rag_advanced.py` |
| **New entry point** | `python pipeline.py` |
| **Process text only** | Import `chunker`, `context_builder` |
| **Custom analysis** | Use `rag_analyzer` classes |
| **Integration** | Import `pipeline` in your code |

## ðŸ“Š Statistics

| Metric | Value |
|--------|-------|
| Total modules | 10 |
| Original file | 691 lines |
| Refactored code | ~1,000 lines |
| Documentation | ~1,000 lines |
| Lines per module | 50-280 |
| Documentation files | 4 |
| Test compatibility | 100% |

## âœ¨ Key Features of Modular Design

âœ… **Each module < 300 lines** â†’ Easy to understand  
âœ… **Clear single responsibility** â†’ Easy to test  
âœ… **Minimal dependencies** â†’ Easy to reuse  
âœ… **Comprehensive documentation** â†’ Easy to maintain  
âœ… **Type hints throughout** â†’ IDE support + safety  
âœ… **Backward compatible** â†’ Existing code works  

## ðŸ”— Cross-References

All modules reference each other cleanly:

```
config.py
    â†‘ Used by: ALL modules
    
models.py
    â†‘ Used by: index_manager, rag_analyzer, pipeline
    
nvidia_client.py
    â†‘ Used by: negation_finder, rag_analyzer, pipeline
    
chunker.py + context_builder.py
    â†‘ Used by: index_manager, pipeline
    
negation_finder.py + graph_rag.py
    â†‘ Used by: rag_analyzer, pipeline
    
index_manager.py + rag_analyzer.py
    â†‘ Used by: pipeline
```

## ðŸ“ž When to Use Each Module

| Need | Module | Method |
|------|--------|--------|
| Split text | `chunker` | `chunk_text()` |
| Embed text | `nvidia_client` | `embed()` |
| LLM call | `nvidia_client` | `chat()` |
| Add context | `context_builder` | `build_context_vector()` |
| Find opposites | `negation_finder` | `find_negated_chunks()` |
| Related chunks | `graph_rag` | `multi_hop_search()` |
| Build index | `index_manager` | `load_or_build()` |
| Extract claims | `rag_analyzer` | `BackstoryExtractor.extract_claims()` |
| Reason | `rag_analyzer` | `ConsistencyAnalyzer.reason_consistency()` |
| Full pipeline | `pipeline` | `run_pipeline()` |

---

## ðŸŽ“ Learning Path

1. **Start**: Read [QUICKSTART.md](QUICKSTART.md)
2. **Understand**: Review [MODULAR_ARCHITECTURE.md](MODULAR_ARCHITECTURE.md)
3. **Explore**: Check [DEPENDENCY_MAP.md](DEPENDENCY_MAP.md)
4. **Implement**: Use examples from each module docstring
5. **Extend**: Modify `config.py` or create custom modules

---

**Happy coding! ðŸš€**
